import { Injectable } from '@nestjs/common';
import { InjectModel } from '@nestjs/mongoose';
import { Model, Types } from 'mongoose';
import { Response, ResponseDocument } from '../schemas/response.schema';
import { Form, FormDocument } from '../schemas/form.schema';
import { AiService } from '../ai/ai.service';
import { randomUUID } from 'crypto';

interface SamplingStrategy {
  description: string;
  rationale: string;
  criteria: string[];
}

export interface AnalyticsTask {
  taskId: string;
  formId: string;
  status: 'running' | 'completed' | 'failed';
  progress: number;
  message: string;
  startedAt: Date;
  completedAt?: Date;
  error?: string;
}

@Injectable()
export class AnalyticsService {
  // In-memory task tracking (for now)
  private activeTasks: Map<string, AnalyticsTask> = new Map();

  constructor(
    @InjectModel(Response.name) private responseModel: Model<ResponseDocument>,
    @InjectModel(Form.name) private formModel: Model<FormDocument>,
    private aiService: AiService,
  ) {
    // Start cleanup job for stale task claims (every 5 minutes)
    setInterval(() => this.cleanupStaleTasks(), 5 * 60 * 1000);
  }

  /**
   * Clean up stale task claims (older than 30 minutes)
   */
  private async cleanupStaleTasks(): Promise<void> {
    try {
      const staleThreshold = new Date(Date.now() - 30 * 60 * 1000); // 30 minutes ago
      
      // Clean up stale response claims
      const responseResult = await this.responseModel.updateMany(
        {
          'metadata.processingTaskId': { $exists: true },
          'metadata.processingStartedAt': { $lt: staleThreshold },
        },
        {
          $unset: {
            'metadata.processingTaskId': '',
            'metadata.processingStartedAt': '',
          }
        }
      ).exec();

      if (responseResult.modifiedCount > 0) {
        console.log(`[Analytics] Cleaned up ${responseResult.modifiedCount} stale response claims`);
      }

      // Clean up stale form locks
      const formResult = await this.formModel.updateMany(
        {
          analyticsLock: { $exists: true },
          analyticsLockStartedAt: { $lt: staleThreshold },
        },
        {
          $unset: {
            analyticsLock: '',
            analyticsLockStartedAt: '',
          }
        }
      ).exec();

      if (formResult.modifiedCount > 0) {
        console.log(`[Analytics] Cleaned up ${formResult.modifiedCount} stale form locks`);
      }
    } catch (error) {
      console.error('[Analytics] Error cleaning up stale tasks:', error);
    }
  }

  /**
   * Get or create analytics task for a form
   * Now creates a NEW task every time to allow parallel processing
   */
  getOrCreateAnalyticsTask(formId: string, forceNew: boolean = false): { taskId: string; existing: boolean; task?: AnalyticsTask } {
    // If forceNew is true, always create a new task (for parallel processing)
    if (forceNew) {
      const taskId = randomUUID();
      const task: AnalyticsTask = {
        taskId,
        formId,
        status: 'running',
        progress: 0,
        message: 'Initializing...',
        startedAt: new Date(),
      };
      this.activeTasks.set(taskId, task);
      console.log('[Analytics] Created NEW task:', taskId, 'for form:', formId);
      return { taskId, existing: false };
    }

    // Check if there's already a running task for this form (legacy behavior)
    for (const [taskId, task] of this.activeTasks.entries()) {
      if (task.formId === formId && task.status === 'running') {
        console.log('[Analytics] Found EXISTING task:', taskId, 'for form:', formId);
        return { taskId, existing: true, task };
      }
    }

    // Create new task if none found
    const taskId = randomUUID();
    const task: AnalyticsTask = {
      taskId,
      formId,
      status: 'running',
      progress: 0,
      message: 'Initializing...',
      startedAt: new Date(),
    };
    this.activeTasks.set(taskId, task);
    console.log('[Analytics] Created task:', taskId, 'for form:', formId);
    
    return { taskId, existing: false };
  }

  /**
   * Get task status
   */
  getTaskStatus(taskId: string): AnalyticsTask | null {
    return this.activeTasks.get(taskId) || null;
  }

  /**
   * Update task progress
   */
  private updateTaskProgress(taskId: string, progress: number, message: string): void {
    const task = this.activeTasks.get(taskId);
    if (task) {
      task.progress = progress;
      task.message = message;
    }
  }

  /**
   * Complete task and release any claimed resources
   */
  private async completeTask(taskId: string, success: boolean, error?: string): Promise<void> {
    const task = this.activeTasks.get(taskId);
    if (task) {
      task.status = success ? 'completed' : 'failed';
      task.completedAt = new Date();
      task.progress = success ? 100 : task.progress;
      if (error) {
        task.error = error;
      }

      // Release form lock
      await this.releaseFormLock(task.formId, taskId);

      // Release any responses still claimed by this task
      try {
        const releaseResult = await this.responseModel.updateMany(
          { 'metadata.processingTaskId': taskId },
          {
            $unset: {
              'metadata.processingTaskId': '',
              'metadata.processingStartedAt': '',
            }
          }
        ).exec();
        
        if (releaseResult.modifiedCount > 0) {
          console.log(`[Analytics][${taskId}] Released ${releaseResult.modifiedCount} claimed responses on task completion`);
        }
      } catch (releaseError) {
        console.error(`[Analytics][${taskId}] Error releasing claimed responses:`, releaseError);
      }
      
      // Clean up completed/failed tasks after 5 minutes
      setTimeout(() => {
        this.activeTasks.delete(taskId);
        console.log(`[Analytics][${taskId}] Task cleaned up from memory`);
      }, 5 * 60 * 1000);
    }
  }

  /**
   * Acquire analytics lock on a form
   * Returns true if lock was acquired, false if form is already locked by another task
   */
  private async acquireFormLock(formId: string, taskId: string): Promise<boolean> {
    try {
      const result = await this.formModel.updateOne(
        {
          _id: formId,
          $or: [
            { analyticsLock: { $exists: false } }, // No lock exists
            { analyticsLock: null }, // Lock is null
            { analyticsLock: taskId }, // Already locked by this task
          ]
        },
        {
          $set: {
            analyticsLock: taskId,
            analyticsLockStartedAt: new Date(),
          }
        }
      ).exec();

      const acquired = result.modifiedCount > 0;
      if (acquired) {
        console.log(`[Analytics][${taskId}] Acquired form lock for form: ${formId}`);
      } else {
        console.log(`[Analytics][${taskId}] Failed to acquire form lock - already locked by another task`);
      }
      return acquired;
    } catch (error) {
      console.error(`[Analytics][${taskId}] Error acquiring form lock:`, error);
      return false;
    }
  }

  /**
   * Release analytics lock on a form
   */
  private async releaseFormLock(formId: string, taskId: string): Promise<void> {
    try {
      const result = await this.formModel.updateOne(
        {
          _id: formId,
          analyticsLock: taskId, // Only release if we own the lock
        },
        {
          $unset: {
            analyticsLock: '',
            analyticsLockStartedAt: '',
          }
        }
      ).exec();

      if (result.modifiedCount > 0) {
        console.log(`[Analytics][${taskId}] Released form lock for form: ${formId}`);
      }
    } catch (error) {
      console.error(`[Analytics][${taskId}] Error releasing form lock:`, error);
    }
  }

  /**
   * Check if analytics should be refreshed based on new responses
   */
  shouldRefreshAnalytics(form: Form, totalResponses: number): boolean {
    const lastAnalytics = form.analytics;
    if (!lastAnalytics) return true; // First time

    const unprocessedCount = totalResponses - lastAnalytics.totalResponsesAnalyzed;
    const percentageIncrease = unprocessedCount / lastAnalytics.totalResponsesAnalyzed;

    // Refresh if:
    // - 10+ new responses AND 10%+ increase, OR
    // - 24+ hours since last update
    return (
      (unprocessedCount >= 10 && percentageIncrease >= 0.1) ||
      (Date.now() - lastAnalytics.lastUpdated.getTime() > 24 * 60 * 60 * 1000)
    );
  }

  // Helper: Calculate topic distribution by counting canonical topics from responses
  // This counts CANONICAL topics (already clustered and stored at response level)
  private calculateTopicDistributionFromResponses(
    responses: ResponseDocument[],
    canonicalTopics: string[]
  ): Record<string, { count: number; percentage: number; associatedQuestions: string[]; sentimentBreakdown: { positive: number; neutral: number; negative: number } }> {
    const distribution: Record<string, { count: number; percentage: number; associatedQuestions: string[]; sentimentBreakdown: { positive: number; neutral: number; negative: number } }> = {};
    
    // Count how many responses contain each canonical topic
    responses.forEach(response => {
      // Use canonicalTopics if available, otherwise fall back to allTopics
      const responseTopics = Array.isArray(response.metadata?.canonicalTopics) 
        ? response.metadata.canonicalTopics 
        : (Array.isArray(response.metadata?.allTopics) ? response.metadata.allTopics : []);
      
      const sentiment = response.metadata?.overallSentiment?.label || 'neutral';
      
      // Track each unique canonical topic from this response (ensure it's a string)
      const uniqueTopicsInResponse = new Set<string>(
        responseTopics.filter((t): t is string => typeof t === 'string')
      );
      
      uniqueTopicsInResponse.forEach(topic => {
        if (!distribution[topic]) {
          distribution[topic] = {
            count: 0,
            percentage: 0,
            associatedQuestions: [],
            sentimentBreakdown: { positive: 0, neutral: 0, negative: 0 }
          };
        }
        
        distribution[topic].count++;
        
        // Track sentiment breakdown
        if (sentiment === 'positive') {
          distribution[topic].sentimentBreakdown.positive++;
        } else if (sentiment === 'negative') {
          distribution[topic].sentimentBreakdown.negative++;
        } else {
          distribution[topic].sentimentBreakdown.neutral++;
        }
      });
    });

    // Calculate percentages
    const totalResponses = responses.length;
    Object.keys(distribution).forEach(topic => {
      distribution[topic].percentage = (distribution[topic].count / totalResponses) * 100;
    });

    return distribution;
  }

  // Helper: Normalize topic name for consistent matching
  private normalizeTopicName(topic: string): string {
    return topic.trim()
      .replace(/\s+/g, ' ') // Normalize whitespace
      .split(' ')
      .map(word => word.charAt(0).toUpperCase() + word.slice(1).toLowerCase())
      .join(' ');
  }

  // Helper: Check if two topics match (case-insensitive, handles variations)
  private topicsMatch(topic1: string, topic2: string): boolean {
    return this.normalizeTopicName(topic1) === this.normalizeTopicName(topic2);
  }

  /**
   * Get form analytics (from cache only - use getFormAnalyticsWithProgress for generation)
   */
  async getFormAnalytics(formId: string): Promise<any> {
    const form = await this.formModel.findById(formId).exec();
    if (!form) {
      throw new Error('Form not found');
    }

    const totalResponses = await this.responseModel.countDocuments({ formId: new Types.ObjectId(formId) }).exec();

    // ONLY return cached data (never auto-generate)
    if (!form.analytics) {
      return {
        formId,
        analytics: null,
        meta: {
          message: 'Analytics not generated yet. Click "Generate Analytics" to create them.',
          totalResponses,
          minimumRequired: 10,
          cacheHit: false,
        },
      };
    }
    
    return {
      formId,
      analytics: form.analytics,
      meta: {
        lastUpdated: form.analytics.lastUpdated,
        responsesAnalyzed: form.analytics.totalResponsesAnalyzed,
        totalResponses,
        cacheHit: true,
      },
    };
  }

  /**
   * Get form analytics with progress updates via callback
   */
  async getFormAnalyticsWithProgress(
    formId: string,
    forceRefresh: boolean = false,
    progressCallback: (update: any) => void,
    taskId?: string
  ): Promise<any> {
    if (!taskId) {
      throw new Error('taskId is required for analytics generation');
    }

    console.log(`[Analytics][${taskId}] Starting analytics generation for form: ${formId}`);
    
    const form = await this.formModel.findById(formId).exec();
    if (!form) {
      throw new Error('Form not found');
    }

    const totalResponses = await this.responseModel.countDocuments({ formId: new Types.ObjectId(formId) }).exec();
    console.log(`[Analytics][${taskId}] Total responses found: ${totalResponses}`);

    if (totalResponses < 10) {
      throw new Error('At least 10 responses required to generate analytics');
    }

    // Try to acquire form lock
    const lockAcquired = await this.acquireFormLock(formId, taskId);
    if (!lockAcquired) {
      const errorMsg = 'Form is currently being processed by another task. Please try again in a few moments.';
      throw new Error(errorMsg);
    }

    // Update task progress
    this.updateTaskProgress(taskId, 0, 'Starting analytics generation...');
    progressCallback({ type: 'start', message: 'Starting analytics generation...', progress: 0, taskId });
    console.log(`[Analytics][${taskId}] Sent start progress`);

    try {
      // Generate new analytics with progress
      const startTime = Date.now();
      await this.generateAnalyticsWithProgress(form, progressCallback, taskId);
      const processingTime = Date.now() - startTime;
      console.log(`[Analytics][${taskId}] Generation complete in ${processingTime}ms`);

      this.updateTaskProgress(taskId, 95, 'Finalizing analytics...');
      progressCallback({ type: 'progress', message: 'Finalizing analytics...', progress: 95, taskId });

      // Refresh form to get updated analytics
      const updatedForm = await this.formModel.findById(formId).exec();

      this.updateTaskProgress(taskId, 100, 'Analytics generation complete!');
      await this.completeTask(taskId, true);
      progressCallback({ type: 'progress', message: 'Analytics generation complete!', progress: 100, taskId });
      console.log(`[Analytics][${taskId}] Analytics saved and finalized`);

      return {
        formId,
        taskId,
        analytics: updatedForm?.analytics,
        meta: {
          lastUpdated: updatedForm?.analytics?.lastUpdated,
          responsesAnalyzed: updatedForm?.analytics?.totalResponsesAnalyzed,
          totalResponses,
          cacheHit: false,
          processingTime: `${processingTime}ms`,
        },
      };
    } catch (error) {
      console.error(`[Analytics][${taskId}] Error during generation:`, error);
      await this.completeTask(taskId, false, error.message);
      throw error;
    }
  }

  /**
   * Process single response using 4-stage chain prompting
   */
  private async processResponseChainPrompting(response: ResponseDocument, form: Form): Promise<void> {
    const responseContext = this.prepareResponseContext(response, form);

    // STAGE 1: Topic Extraction (Grounded Theory - In-vivo Coding)
    const topicPrompt = `You are a qualitative researcher performing in-vivo coding.
Extract topics using respondent's own words (in-vivo codes).
Focus on what the respondent actually said, not interpretation.

Extract in-vivo topics from this response:

${responseContext}

Return JSON:
{
  "topics": [
    {
      "topic": "normalized category name",
      "inVivoCode": "exact phrase from response",
      "confidence": 0-1,
      "isPrimary": boolean,
      "sourceQuestions": ["questionId1"]
    }
  ],
  "overallConfidence": 0-1
}`;

    const topicAnalysisRaw = await this.aiService['invokeModelRaw'](topicPrompt);
    const topicAnalysis = JSON.parse(topicAnalysisRaw);

    // STAGE 2: Sentiment Analysis (Per-Question + Overall)
    const sentimentPrompt = `You are analyzing sentiment in survey responses.
For each answer, determine sentiment and what specifically is being evaluated (sentiment targets).

Analyze sentiment for each answer:

${responseContext}

Return JSON:
{
  "questionSentiments": [
    {
      "questionId": "string",
      "sentiment": "positive|neutral|negative|ambivalent",
      "score": -1 to 1,
      "intensity": 0 to 1,
      "targets": [{"target": "what's evaluated", "sentiment": "pos|neu|neg"}],
      "confidence": 0-1
    }
  ],
  "overallSentiment": {
    "sentiment": "positive|neutral|negative|ambivalent",
    "score": -1 to 1,
    "emotionalTone": "frustrated|satisfied|neutral|confused etc.",
    "confidence": 0-1
  }
}`;

    const sentimentAnalysisRaw = await this.aiService['invokeModelRaw'](sentimentPrompt);
    const sentimentAnalysis = JSON.parse(sentimentAnalysisRaw);

    // STAGE 3: Discourse & Frame Analysis (ONLY for substantial text)
    let discourseAnalysis: any = null;
    if (this.shouldAnalyzeDiscourse(response)) {
      const discoursePrompt = `You are analyzing discourse structure and interpretive frames.
Identify how the respondent frames their experience.

Analyze discourse frames and narrative:

${responseContext}

Return JSON:
{
  "frames": [
    {
      "type": "problem|solution|complaint|praise|narrative",
      "description": "how topic is framed",
      "evidence": "quote from response",
      "implicitValues": ["assumptions being made"]
    }
  ],
  "narrativeStructure": {
    "hasArc": boolean,
    "type": "linear|episodic|argumentative|evaluative",
    "keyMoments": ["important parts"]
  },
  "powerDynamics": "description if applicable"
}`;

      const discourseAnalysisRaw = await this.aiService['invokeModelRaw'](discoursePrompt);
      discourseAnalysis = JSON.parse(discourseAnalysisRaw);
    }

    // STAGE 4: Key Quotes & Evidence Extraction
    const quotesPrompt = `You are extracting significant quotes and evidence.
Preserve exact wording. Select quotes that represent key themes.

Extract key quotes from this response:

${responseContext}

Return JSON:
{
  "keyQuotes": [
    {
      "quote": "exact text",
      "significance": "why this quote matters",
      "questionId": "string",
      "relatedTopics": ["topic1", "topic2"]
    }
  ],
  "representativeness": "typical|deviant|mixed",
  "responseQuality": {
    "depth": "superficial|moderate|deep",
    "completeness": 0-1,
    "coherence": 0-1
  }
}`;

    const quotesAnalysisRaw = await this.aiService['invokeModelRaw'](quotesPrompt);
    const quotesAnalysis = JSON.parse(quotesAnalysisRaw);

    // Update response with metadata
    response.metadata = {
      ...response.metadata,
      topics: topicAnalysis.topics,
      allTopics: topicAnalysis.topics.map((t: any) => t.topic),
      sentiment: sentimentAnalysis,
      discourse: discourseAnalysis,
      quotes: quotesAnalysis,
      processedForAnalytics: true,
      lastAnalyzed: new Date(),
      fullTextPreserved: true,
      overallSentiment: sentimentAnalysis.overallSentiment,
    };

    // Update per-answer metadata
    response.answers = response.answers.map(answer => {
      const answerTopics = topicAnalysis.topics.filter((t: any) =>
        t.sourceQuestions.includes(answer.questionId)
      );
      const answerSentiment = sentimentAnalysis.questionSentiments.find((s: any) =>
        s.questionId === answer.questionId
      );

      if (answerTopics.length > 0 || answerSentiment) {
        answer.metadata = {
          extractedTopics: answerTopics.map((t: any) => t.topic),
          topicConfidence: answerTopics.reduce((sum: number, t: any) => sum + t.confidence, 0) / (answerTopics.length || 1),
          sentiment: answerSentiment ? {
            label: answerSentiment.sentiment,
            score: answerSentiment.score,
            confidence: answerSentiment.confidence,
            intensity: answerSentiment.intensity,
            targets: answerSentiment.targets,
          } : undefined,
          textLength: answer.value?.length || 0,
        };
      }
      return answer;
    });

    await response.save();
  }

  /**
   * Generate aggregate analytics with progress updates
   */
  private async generateAnalyticsWithProgress(
    form: FormDocument, 
    progressCallback: (update: any) => void,
    taskId?: string
  ): Promise<void> {
    if (!taskId) {
      throw new Error('taskId is required for analytics generation');
    }

    // Step 1: Process individual responses with OPTIMIZED HYBRID BATCH
    // - Sentiment analyzed once per response (overall only)
    // - Question-level sentiment calculated mathematically later
    // - 3 parallel API calls per chunk (topics, sentiment, quotes)
    await this.processIndividualResponsesWithHybridBatch(form, progressCallback, taskId);

    this.updateTaskProgress(taskId, 60, 'Loading processed responses...');
    progressCallback({ type: 'progress', message: 'Loading processed responses...', progress: 60, taskId });

    // Step 2: Get all processed responses
    const responses = await this.responseModel.find({
      formId: form._id,
      'metadata.processedForAnalytics': true,
    }).exec();

    if (responses.length === 0) {
      form.analytics = {
        lastUpdated: new Date(),
        totalResponsesAnalyzed: 0,
        cacheVersion: 1,
        topics: {
          distribution: {},
          topTopics: [],
          dominantThemes: [],
          emergingThemes: [],
          counterNarratives: [],
        },
        sentiment: {
          overall: { positive: 0, neutral: 0, negative: 0, averageScore: 0 },
          byQuestion: {},
          emotionalTones: [],
          dominantTags: [],
        },
        correlations: {
          byQuestion: {},
          questionPairs: [],
          topCorrelations: [],
        },
        quotes: {
          representative: [],
          highQuality: [],
          deviant: [],
        },
        deviantCases: [],
        insights: {
          summary: 'No responses to analyze yet.',
          keyFindings: [],
          recommendations: [],
        },
      };
      await form.save();
      return;
    }

    progressCallback({ type: 'progress', message: 'Applying theoretical sampling...', progress: 65 });

    // Step 3: Theoretical sampling
    const samplingStrategy = this.determineTheoreticalSampling(responses, form);
    const sample = this.theoreticalSample(responses, samplingStrategy);

    progressCallback({ type: 'progress', message: 'Computing statistics...', progress: 70 });

    // Step 4: Compute local statistics (no LLM needed)
    const statistics = {
      totalResponses: responses.length,
      topicFrequencies: this.calculateTopicFrequencies(responses),
      sentimentDistribution: this.calculateSentimentDistribution(responses),
      dataQuality: this.assessDataQuality(responses),
    };

    progressCallback({ type: 'progress', message: 'Generating aggregate insights...', progress: 75, taskId });

    // Step 5: Run 6-stage chain prompting for aggregate insights
    await this.generateAggregateInsightsWithProgress(form, responses, sample, statistics, progressCallback, taskId);
  }

  /**
   * Process individual responses with progress updates
   * Isolated by taskId to prevent interference between parallel tasks
   */
  private async processIndividualResponsesWithProgress(
    form: FormDocument,
    progressCallback: (update: any) => void,
    taskId?: string
  ): Promise<void> {
    if (!taskId) {
      throw new Error('taskId is required for isolated processing');
    }

    console.log(`[Analytics][${taskId}] Starting individual response processing`);

    // Claim unprocessed responses for this task atomically
    // This prevents other tasks from processing the same responses
    const claimResult = await this.responseModel.updateMany(
      {
        formId: form._id,
        'metadata.processedForAnalytics': false,
        'metadata.processingTaskId': { $exists: false }, // Not claimed by another task
      },
      {
        $set: {
          'metadata.processingTaskId': taskId,
          'metadata.processingStartedAt': new Date(),
        }
      }
    ).exec();

    console.log(`[Analytics][${taskId}] Claimed ${claimResult.modifiedCount} responses for processing`);

    // Get responses claimed by this task
    const claimedResponses = await this.responseModel.find({
      formId: form._id,
      'metadata.processingTaskId': taskId,
    }).exec();

    const textResponses = claimedResponses.filter(r => r.metadata.hasTextContent);
    const totalResponses = await this.responseModel.countDocuments({ formId: form._id }).exec();

    if (textResponses.length === 0) {
      // Mark all claimed responses as processed (even if no text)
      await this.responseModel.updateMany(
        {
          formId: form._id,
          'metadata.processingTaskId': taskId,
        },
        {
          $set: {
            'metadata.processedForAnalytics': true,
            'metadata.lastAnalyzed': new Date(),
          },
          $unset: {
            'metadata.processingTaskId': '',
            'metadata.processingStartedAt': '',
          }
        }
      ).exec();
      
      this.updateTaskProgress(taskId, 50, 'No text responses to process');
      progressCallback({ 
        type: 'progress', 
        message: 'No text responses to process', 
        progress: 50,
        taskId,
        stats: {
          stage: 'Individual Response Processing',
          processedResponses: 0,
          totalResponses: totalResponses,
          currentResponse: 0,
          totalToProcess: 0
        }
      });
      return;
    }

    const total = textResponses.length;
    let current = 0;

    progressCallback({ 
      type: 'progress', 
      message: `Starting to process ${total} responses...`, 
      progress: 5,
      taskId,
      stats: {
        stage: 'Individual Response Processing',
        processedResponses: 0,
        totalResponses: totalResponses,
        currentResponse: 0,
        totalToProcess: total
      }
    });

    // Process each response with chain prompting
    for (const response of textResponses) {
      current++;
      const percentage = 5 + Math.floor((current / total) * 50); // 5% to 55%
      
      if (taskId) {
        this.updateTaskProgress(taskId, percentage, `Processing response ${current}/${total}...`);
      }
      
      progressCallback({ 
        type: 'progress', 
        message: `Processing response ${current}/${total}...`, 
        progress: percentage,
        taskId,
        stats: {
          stage: 'Individual Response Processing',
          processedResponses: current - 1,
          totalResponses: totalResponses,
          currentResponse: current,
          totalToProcess: total
        }
      });

      await this.processResponseChainPromptingWithProgress(response, form, current, total, progressCallback, taskId);
    }

    // Release task claim and mark as processed
    console.log(`[Analytics][${taskId}] Releasing claim on ${total} processed responses`);
    await this.responseModel.updateMany(
      {
        formId: form._id,
        'metadata.processingTaskId': taskId,
      },
      {
        $set: {
          'metadata.processedForAnalytics': true,
          'metadata.lastAnalyzed': new Date(),
        },
        $unset: {
          'metadata.processingTaskId': '',
          'metadata.processingStartedAt': '',
        }
      }
    ).exec();

    this.updateTaskProgress(taskId, 55, `All ${total} responses processed`);
    
    progressCallback({ 
      type: 'progress', 
      message: `All ${total} responses processed`, 
      progress: 55,
      taskId,
      stats: {
        stage: 'Individual Response Processing Complete',
        processedResponses: total,
        totalResponses: totalResponses,
        currentResponse: total,
        totalToProcess: total
      }
    });
  }

  /**
   * Process single response using 4-stage chain prompting with progress
   */
  private async processResponseChainPromptingWithProgress(
    response: ResponseDocument,
    form: Form,
    current: number,
    total: number,
    progressCallback: (update: any) => void,
    taskId?: string
  ): Promise<void> {
    const responseContext = this.prepareResponseContext(response, form);

    // STAGE 1: Topic Extraction
    progressCallback({
      type: 'stage',
      message: `Response ${current}/${total}: Extracting topics...`,
      stage: 'Topic Extraction',
      substage: '1/4',
      taskId
    });

    const topicPrompt = `You are a qualitative researcher performing in-vivo coding.
Extract topics using respondent's own words (in-vivo codes).
Focus on what the respondent actually said, not interpretation.

Extract in-vivo topics from this response:

${responseContext}

Return JSON:
{
  "topics": [
    {
      "topic": "normalized category name",
      "inVivoCode": "exact phrase from response",
      "confidence": 0-1,
      "isPrimary": boolean,
      "sourceQuestions": ["questionId1"]
    }
  ],
  "overallConfidence": 0-1
}`;

    const topicAnalysisRaw = await this.aiService['invokeModelRaw'](topicPrompt);
    const topicAnalysis = JSON.parse(topicAnalysisRaw);

    // STAGE 2: Sentiment Analysis
    progressCallback({
      type: 'stage',
      message: `Response ${current}/${total}: Analyzing sentiment...`,
      stage: 'Sentiment Analysis',
      substage: '2/4',
      taskId
    });

    const sentimentPrompt = `You are analyzing sentiment in survey responses.
For each answer, determine sentiment and what specifically is being evaluated (sentiment targets).

Analyze sentiment for each answer:

${responseContext}

Return JSON:
{
  "questionSentiments": [
    {
      "questionId": "string",
      "sentiment": "positive|neutral|negative|ambivalent",
      "score": -1 to 1,
      "intensity": 0 to 1,
      "targets": [{"target": "what's evaluated", "sentiment": "pos|neu|neg"}],
      "confidence": 0-1
    }
  ],
  "overallSentiment": {
    "sentiment": "positive|neutral|negative|ambivalent",
    "score": -1 to 1,
    "emotionalTone": "frustrated|satisfied|neutral|confused etc.",
    "confidence": 0-1
  }
}`;

    const sentimentAnalysisRaw = await this.aiService['invokeModelRaw'](sentimentPrompt);
    const sentimentAnalysis = JSON.parse(sentimentAnalysisRaw);

    // STAGE 3: Discourse & Frame Analysis (ONLY for substantial text)
    let discourseAnalysis: any = null;
    if (this.shouldAnalyzeDiscourse(response)) {
      progressCallback({
        type: 'stage',
        message: `Response ${current}/${total}: Analyzing discourse...`,
        stage: 'Discourse Analysis',
        substage: '3/4',
        taskId
      });

      const discoursePrompt = `You are analyzing discourse structure and interpretive frames.
Identify how the respondent frames their experience.

Analyze discourse frames and narrative:

${responseContext}

Return JSON:
{
  "frames": [
    {
      "type": "problem|solution|complaint|praise|narrative",
      "description": "how topic is framed",
      "evidence": "quote from response",
      "confidence": 0-1
    }
  ],
  "narrativeStructure": {
    "hasNarrative": boolean,
    "arcType": "problem-solution|chronological|emotional journey|etc",
    "coherence": 0-1
  }
}`;

      const discourseAnalysisRaw = await this.aiService['invokeModelRaw'](discoursePrompt);
      discourseAnalysis = JSON.parse(discourseAnalysisRaw);
    }

    // STAGE 4: Quote Selection & Representativeness
    progressCallback({
      type: 'stage',
      message: `Response ${current}/${total}: Selecting quotes...`,
      stage: 'Quote Selection',
      substage: '4/4',
      taskId
    });

    const quotePrompt = `You are selecting representative quotes.
Choose quotes that best illustrate topics and sentiment.

Select best quotes:

${responseContext}

Previously identified topics: ${JSON.stringify(topicAnalysis.topics.map(t => t.topic))}
Overall sentiment: ${sentimentAnalysis.overallSentiment.sentiment}

Return JSON:
{
  "quotes": [
    {
      "text": "exact quote",
      "questionId": "string",
      "topics": ["topic1"],
      "representativeness": 0-1,
      "quality": {
        "clarity": 0-1,
        "specificity": 0-1,
        "emotionalResonance": 0-1
      }
    }
  ]
}`;

    const quoteAnalysisRaw = await this.aiService['invokeModelRaw'](quotePrompt);
    const quoteAnalysis = JSON.parse(quoteAnalysisRaw);

    // Save enriched response
    response.metadata.processedForAnalytics = true;
    response.metadata.lastAnalyzed = new Date();
    response.metadata.extractedKeywords = topicAnalysis.topics.map(t => t.topic);

    response.answers = response.answers.map(answer => {
      const qSentiment = sentimentAnalysis.questionSentiments.find(s => s.questionId === answer.questionId);
      const topics = topicAnalysis.topics.filter(t => t.sourceQuestions.includes(answer.questionId));
      const quotes = quoteAnalysis.quotes.filter(q => q.questionId === answer.questionId);

      if (qSentiment || topics.length > 0 || quotes.length > 0) {
        answer.metadata = {
          extractedTopics: topics.map(t => t.topic),
          topicConfidence: topics.reduce((sum, t) => sum + t.confidence, 0) / (topics.length || 1),
          sentiment: qSentiment ? {
            label: qSentiment.sentiment,
            score: qSentiment.score,
            intensity: qSentiment.intensity,
            targets: qSentiment.targets,
            confidence: qSentiment.confidence,
          } : undefined,
          textLength: answer.value?.length || 0,
        };
      }
      return answer;
    });

    await response.save();
  }

  // ===== HELPER FUNCTIONS =====

  private prepareResponseContext(response: ResponseDocument, form: Form): string {
    return response.answers
      .filter(a => {
        const q = form.questions.find(q => q.id === a.questionId);
        return q && ['text', 'textarea'].includes(q.type);
      })
      .map(a => {
        const question = form.questions.find(q => q.id === a.questionId);
        return `Question ID: ${a.questionId}\nQ: ${question?.title}\nA: ${a.value}`;
      })
      .join('\n\n');
  }

  private shouldAnalyzeDiscourse(response: ResponseDocument): boolean {
    const totalTextLength = response.answers.reduce(
      (sum, ans) => sum + (ans.value?.length || 0),
      0
    );
    // Skip discourse analysis for short responses (< 200 chars total)
    return totalTextLength >= 200;
  }

  /**
   * Calculate topic co-occurrence matrix
   * Finds which topics frequently appear together in the same responses
   */
  private calculateTopicCooccurrence(responses: ResponseDocument[]): Array<{
    topic1: string;
    topic2: string;
    frequency: number;
    relationship: string;
  }> {
    const cooccurrenceMap = new Map<string, number>();
    const topicPairCounts = new Map<string, Set<string>>();

    // Count topic co-occurrences
    responses.forEach(response => {
      const topics = response.metadata?.canonicalTopics || response.metadata?.allTopics || [];
      if (topics.length < 2) return;

      // For each pair of topics in this response
      for (let i = 0; i < topics.length; i++) {
        for (let j = i + 1; j < topics.length; j++) {
          const topic1 = topics[i];
          const topic2 = topics[j];
          
          // Create consistent key (alphabetically sorted)
          const key = [topic1, topic2].sort().join('|||');
          
          cooccurrenceMap.set(key, (cooccurrenceMap.get(key) || 0) + 1);
          
          // Track unique response IDs for this pair
          if (!topicPairCounts.has(key)) {
            topicPairCounts.set(key, new Set());
          }
          const pairSet = topicPairCounts.get(key);
          if (pairSet && response._id) {
            pairSet.add(String(response._id));
          }
        }
      }
    });

    // Convert to array and sort by frequency
    const cooccurrences = Array.from(cooccurrenceMap.entries())
      .map(([key, frequency]) => {
        const [topic1, topic2] = key.split('|||');
        const uniqueResponses = topicPairCounts.get(key)?.size || 0;
        
        // Determine relationship strength
        let relationship = 'weak';
        if (frequency >= 5) relationship = 'strong';
        else if (frequency >= 3) relationship = 'moderate';
        
        return {
          topic1,
          topic2,
          frequency,
          relationship,
          uniqueResponses
        };
      })
      .sort((a, b) => b.frequency - a.frequency)
      .slice(0, 20); // Top 20 co-occurrences

    return cooccurrences;
  }

  /**
   * Calculate topic-sentiment correlations
   * Shows which topics are associated with which sentiments
   */
  private calculateTopicSentimentCorrelation(responses: ResponseDocument[]): Array<{
    topic: string;
    sentiment: {
      positive: number;
      neutral: number;
      negative: number;
    };
    averageScore: number;
    dominantSentiment: string;
    responseCount: number;
  }> {
    const topicSentimentMap = new Map<string, {
      positive: number;
      neutral: number;
      negative: number;
      scores: number[];
    }>();

    // Aggregate sentiment data per topic
    responses.forEach(response => {
      const topics = response.metadata?.canonicalTopics || response.metadata?.allTopics || [];
      const sentiment = response.metadata?.overallSentiment;
      
      if (!sentiment || topics.length === 0) return;

      topics.forEach(topic => {
        if (!topicSentimentMap.has(topic)) {
          topicSentimentMap.set(topic, {
            positive: 0,
            neutral: 0,
            negative: 0,
            scores: []
          });
        }

        const data = topicSentimentMap.get(topic);
        if (!data) return; // Use return instead of continue in forEach
        
        const label = sentiment.label || 'neutral';
        
        if (label === 'positive') data.positive++;
        else if (label === 'negative') data.negative++;
        else data.neutral++;
        
        if (typeof sentiment.score === 'number') {
          data.scores.push(sentiment.score);
        }
      });
    });

    // Convert to array with calculated metrics
    const correlations = Array.from(topicSentimentMap.entries())
      .map(([topic, data]) => {
        const total = data.positive + data.neutral + data.negative;
        const avgScore = data.scores.length > 0
          ? data.scores.reduce((sum, s) => sum + s, 0) / data.scores.length
          : 0;

        // Determine dominant sentiment
        let dominantSentiment = 'neutral';
        const posPercent = (data.positive / total) * 100;
        const negPercent = (data.negative / total) * 100;
        
        if (posPercent > 60) dominantSentiment = 'positive';
        else if (negPercent > 60) dominantSentiment = 'negative';
        else if (posPercent > 40 && negPercent < 20) dominantSentiment = 'mostly positive';
        else if (negPercent > 40 && posPercent < 20) dominantSentiment = 'mostly negative';
        else dominantSentiment = 'mixed';

        return {
          topic,
          sentiment: {
            positive: Math.round((data.positive / total) * 100),
            neutral: Math.round((data.neutral / total) * 100),
            negative: Math.round((data.negative / total) * 100),
          },
          averageScore: Math.round(avgScore * 100) / 100,
          dominantSentiment,
          responseCount: total
        };
      })
      .sort((a, b) => b.responseCount - a.responseCount)
      .slice(0, 15); // Top 15 topics

    return correlations;
  }

  /**
   * Calculate correlations between closed question answers and topics from open questions
   * This reveals demographic patterns and answer preferences related to discussion topics
   */
  private calculateClosedQuestionTopicCorrelations(
    form: FormDocument,
    responses: ResponseDocument[]
  ): Array<{
    questionId: string;
    questionTitle: string;
    questionType: string;
    correlations: Array<{
      answerValue: string;
      topicDistribution: Array<{
        topic: string;
        percentage: number;
        count: number;
      }>;
      responseCount: number;
    }>;
  }> {
    // Identify closed questions (dropdown, radio, checkbox)
    const closedQuestions = form.questions.filter(q => 
      ['dropdown', 'radio', 'checkbox'].includes(q.type)
    );

    if (closedQuestions.length === 0) {
      return [];
    }

    const correlations = closedQuestions.map(question => {
      // Group responses by answer value
      const answerGroups = new Map<string, ResponseDocument[]>();

      responses.forEach(response => {
        const answer = response.answers.find(a => a.questionId === question.id);
        if (!answer || !answer.value) return;

        // Handle both single values and arrays (for checkbox questions)
        const values = Array.isArray(answer.value) ? answer.value : [answer.value];

        values.forEach(value => {
          const valueStr = String(value);
          if (!answerGroups.has(valueStr)) {
            answerGroups.set(valueStr, []);
          }
          answerGroups.get(valueStr)!.push(response);
        });
      });

      // Calculate topic distribution for each answer value
      const answerCorrelations = Array.from(answerGroups.entries()).map(([answerValue, groupResponses]) => {
        // Count topics across responses in this group
        const topicCounts = new Map<string, number>();
        
        groupResponses.forEach(response => {
          const topics = response.metadata?.canonicalTopics || response.metadata?.allTopics || [];
          topics.forEach(topic => {
            topicCounts.set(topic, (topicCounts.get(topic) || 0) + 1);
          });
        });

        // Convert to distribution array
        const totalTopicMentions = Array.from(topicCounts.values()).reduce((sum, count) => sum + count, 0);
        const topicDistribution = Array.from(topicCounts.entries())
          .map(([topic, count]) => ({
            topic,
            percentage: totalTopicMentions > 0 ? Math.round((count / totalTopicMentions) * 100) : 0,
            count
          }))
          .sort((a, b) => b.count - a.count)
          .slice(0, 10); // Top 10 topics per answer value

        return {
          answerValue,
          topicDistribution,
          responseCount: groupResponses.length
        };
      })
      .filter(ac => ac.responseCount >= 2) // Only include answer values with at least 2 responses
      .sort((a, b) => b.responseCount - a.responseCount);

      return {
        questionId: question.id,
        questionTitle: question.title,
        questionType: question.type,
        correlations: answerCorrelations
      };
    })
    .filter(qc => qc.correlations.length > 0); // Only include questions with meaningful correlations

    return correlations;
  }

  /**
   * OPTIMIZED HYBRID BATCH PROCESSING WITH CANONICAL CLUSTERING
   * Key improvements:
   * 1. Sentiment analyzed ONCE per response (overall only, not per-question)
   * 2. Question-level sentiment calculated mathematically from aggregates
   * 3. CANONICAL TOPICS: After initial extraction, cluster all topics and store canonical versions on each response
   * 4. This makes aggregation trivial - just count canonical topics across responses
   */
  private async processIndividualResponsesWithHybridBatch(
    form: FormDocument,
    progressCallback: (update: any) => void,
    taskId: string
  ): Promise<void> {
    console.log(`[Analytics][${taskId}] Starting HYBRID BATCH processing`);

    const OPTIMAL_CHUNK_SIZE = 15;
    const MAX_CHUNK_SIZE = 25;
    const MAX_CONCURRENCY = 4;

    // Claim unprocessed responses
    const claimResult = await this.responseModel.updateMany(
      {
        formId: form._id,
        'metadata.processedForAnalytics': false,
        'metadata.processingTaskId': { $exists: false },
      },
      {
        $set: {
          'metadata.processingTaskId': taskId,
          'metadata.processingStartedAt': new Date(),
        }
      }
    ).exec();

    console.log(`[Analytics][${taskId}] Claimed ${claimResult.modifiedCount} responses`);

    const claimedResponses = await this.responseModel.find({
      formId: form._id,
      'metadata.processingTaskId': taskId,
    }).exec();

    const textResponses = claimedResponses.filter(r => r.metadata.hasTextContent);
    const emptyResponses = claimedResponses.filter(r => !r.metadata.hasTextContent);
    const totalResponses = await this.responseModel.countDocuments({ formId: form._id }).exec();

    // Mark empty responses as processed immediately (no analysis needed)
    if (emptyResponses.length > 0) {
      console.log(`[Analytics][${taskId}] Marking ${emptyResponses.length} empty responses as processed`);
      await this.responseModel.updateMany(
        { _id: { $in: emptyResponses.map(r => r._id) } },
        {
          $set: {
            'metadata.processedForAnalytics': true,
            'metadata.lastAnalyzed': new Date(),
            'metadata.allTopics': [],
            'metadata.canonicalTopics': [],
            'metadata.primaryTopics': [],
            'metadata.overallSentiment': null,
            'metadata.quotes': {
              keyQuotes: [],
              representativeness: 'typical',
              responseQuality: {
                depth: 'superficial',
                completeness: 0,
                coherence: 0
              }
            }
          },
          $unset: {
            'metadata.processingTaskId': '',
            'metadata.processingStartedAt': ''
          }
        }
      ).exec();
    }

    if (textResponses.length === 0) {
      await this.releaseTaskClaim(taskId, form._id as Types.ObjectId);
      progressCallback({ type: 'progress', message: 'No text responses', progress: 50, taskId });
      return;
    }

    // Calculate chunking strategy
    const avgLength = this.calculateAvgResponseLength(textResponses);
    const chunkSize = this.adaptiveChunkSize(textResponses.length, avgLength);
    const chunks = this.createResponseChunks(textResponses, chunkSize);

    progressCallback({
      type: 'progress',
      message: `Processing ${textResponses.length} responses in ${chunks.length} chunks...`,
      progress: 5,
      taskId,
      stats: { totalResponses, chunksToProcess: chunks.length }
    });

    // PHASE 1: Extract raw topics, sentiment, and quotes
    let processedChunks = 0;
    for (let i = 0; i < chunks.length; i += MAX_CONCURRENCY) {
      const wave = chunks.slice(i, i + MAX_CONCURRENCY);
      const waveNumber = Math.floor(i / MAX_CONCURRENCY) + 1;
      
      // Calculate response range for this wave
      const startResponse = processedChunks * chunks[0].length + 1;
      const endResponse = Math.min((processedChunks + wave.length) * chunks[0].length, textResponses.length);
      const totalWaves = Math.ceil(chunks.length / MAX_CONCURRENCY);
      
      progressCallback({
        type: 'progress',
        message: totalWaves > 1 
          ? `Analyzing topics, sentiment & quotes for responses ${startResponse}-${endResponse} (batch ${waveNumber}/${totalWaves})...`
          : `Analyzing topics, sentiment & quotes for ${textResponses.length} responses...`,
        progress: 5 + Math.floor((processedChunks / chunks.length) * 40), // 5% to 45%
        taskId
      });

      const waveResults = await Promise.all(
        wave.map((chunk, waveIdx) => 
          this.processChunkInParallel(chunk, form, i + waveIdx, taskId)
        )
      );

      await this.saveChunkResults(waveResults);
      processedChunks += wave.length;
    }

    // PHASE 2: Cluster all extracted topics into canonical categories
    progressCallback({
      type: 'progress',
      message: 'Clustering topics into canonical categories...',
      progress: 45,
      taskId
    });

    await this.clusterAndStoreCanonicalTopics(form._id as Types.ObjectId, taskId, progressCallback);

    await this.releaseTaskClaim(taskId, form._id as Types.ObjectId);
    progressCallback({ type: 'progress', message: 'All responses processed', progress: 55, taskId });
  }

  private calculateAvgResponseLength(responses: ResponseDocument[]): number {
    const totalLength = responses.reduce((sum, r) => {
      return sum + r.answers.reduce((ansSum, ans) => ansSum + (ans.value?.length || 0), 0);
    }, 0);
    return totalLength / responses.length;
  }

  private adaptiveChunkSize(responseCount: number, avgLength: number): number {
    if (avgLength > 500) return Math.min(10, 15);
    if (avgLength > 200) return 15;
    return 25;
  }

  private createResponseChunks(responses: ResponseDocument[], chunkSize: number): ResponseDocument[][] {
    const chunks: ResponseDocument[][] = [];
    for (let i = 0; i < responses.length; i += chunkSize) {
      chunks.push(responses.slice(i, i + chunkSize));
    }
    return chunks;
  }

  /**
   * Process chunk: 3 features in parallel (topics, sentiment-overall, quotes)
   * NO per-question sentiment - that's calculated mathematically later
   */
  private async processChunkInParallel(
    chunk: ResponseDocument[],
    form: Form,
    chunkIndex: number,
    taskId: string
  ): Promise<any> {
    const topicPrompt = this.createTopicExtractionPrompt(chunk, form);
    const sentimentPrompt = this.createOverallSentimentPrompt(chunk, form); // SIMPLIFIED!
    const quotePrompt = this.createQuoteExtractionPrompt(chunk, form);

    try {
      // Batch the 3 analysis types in parallel
      // Each prompt specifies its expected JSON schema in the prompt text
      // The AI service enforces json_object response format
      const results = await this.aiService.batchAnalyze(
        [topicPrompt, sentimentPrompt, quotePrompt],
        { 
          temperature: 0.3, 
          maxTokens: 4000, 
          maxConcurrency: 3
        }
      );

      console.log(`[processChunkInParallel][${taskId}] Raw results lengths:`, results.map(r => r.length));
      console.log(`[processChunkInParallel][${taskId}] Topics result preview:`, results[0].substring(0, 200));
      
      const parsedTopics = JSON.parse(results[0]);
      const parsedSentiment = JSON.parse(results[1]);
      const parsedQuotes = JSON.parse(results[2]);

      console.log(`[processChunkInParallel][${taskId}] Parsed structures:`, {
        topicsIsArray: Array.isArray(parsedTopics),
        sentimentIsArray: Array.isArray(parsedSentiment),
        quotesIsArray: Array.isArray(parsedQuotes),
        topicsType: typeof parsedTopics,
        sentimentType: typeof parsedSentiment,
        quotesType: typeof parsedQuotes,
        topicsKeys: Object.keys(parsedTopics),
        sentimentKeys: Object.keys(parsedSentiment),
        quotesKeys: Object.keys(parsedQuotes)
      });

      // Extract results array from wrapper object
      const topicsArray = Array.isArray(parsedTopics) ? parsedTopics : (parsedTopics.results || []);
      const sentimentArray = Array.isArray(parsedSentiment) ? parsedSentiment : (parsedSentiment.results || []);
      const quotesArray = Array.isArray(parsedQuotes) ? parsedQuotes : (parsedQuotes.results || []);

      console.log(`[processChunkInParallel][${taskId}] Extracted arrays:`, {
        topicsLength: topicsArray.length,
        sentimentLength: sentimentArray.length,
        quotesLength: quotesArray.length
      });

      return {
        chunkIndex,
        topics: topicsArray,
        sentiment: sentimentArray,
        quotes: quotesArray
      };
    } catch (error) {
      console.error(`[Analytics][${taskId}] Error in chunk ${chunkIndex}:`, error);
      throw error;
    }
  }

  private createTopicExtractionPrompt(responses: ResponseDocument[], form: Form): string {
    const responsesData = responses.map((r) => ({
      responseId: (r._id as Types.ObjectId).toString(),
      answers: r.answers.map(ans => {
        const question = form.questions.find(q => q.id === ans.questionId);
        return { questionId: ans.questionId, questionTitle: question?.title, value: ans.value };
      })
    }));

    return `CRITICAL: You MUST return ONLY valid JSON. No explanations, no markdown, no prose.

Task: Extract topics from ${responses.length} survey responses using in-vivo coding.

Responses:
${JSON.stringify(responsesData, null, 2)}

REQUIRED OUTPUT FORMAT (valid JSON object with "results" array):
{
  "results": [{
    "responseId": "string",
    "topics": [
      {
        "topic": "string",
        "inVivoCode": "string",
        "confidence": 0.0,
        "isPrimary": true
      }
    ]
  }]
}

RULES:
- Output MUST be valid JSON object (test with JSON.parse)
- Root must be an object with "results" array
- MUST include ALL ${responses.length} responses in results array (one per response)
- Topics can be empty array [] if no clear topics found
- Do NOT include any text before or after the JSON
- Do NOT use markdown code blocks
- Do NOT add explanations
- Confidence must be between 0 and 1
- isPrimary must be boolean (true/false)`;
  }

  /**
   * OPTIMIZED: Analyze ONLY overall sentiment per response
   * No per-question sentiment (calculated mathematically later)
   */
  private createOverallSentimentPrompt(responses: ResponseDocument[], form: Form): string {
    const responsesData = responses.map((r) => ({
      responseId: (r._id as Types.ObjectId).toString(),
      answers: r.answers.map(ans => {
        const question = form.questions.find(q => q.id === ans.questionId);
        return { questionId: ans.questionId, questionTitle: question?.title, value: ans.value };
      })
    }));

    return `CRITICAL: You MUST return ONLY valid JSON. No explanations, no markdown, no prose.

Task: Analyze OVERALL sentiment for ${responses.length} survey responses.
Focus on the respondent's general feeling/tone across ALL their answers.

Responses:
${JSON.stringify(responsesData, null, 2)}

REQUIRED OUTPUT FORMAT (valid JSON object with "results" array):
{
  "results": [{
    "responseId": "string",
    "overallSentiment": {
      "sentiment": "positive",
      "score": 0.5,
      "emotionalTone": "satisfied",
      "confidence": 0.8,
      "reasoning": "brief explanation"
    }
  }]
}

RULES:
- Output MUST be valid JSON object (test with JSON.parse)
- Root must be an object with "results" array
- MUST include ALL ${responses.length} responses in results array (one per response)
- Do NOT include any text before or after the JSON
- Do NOT use markdown code blocks
- Do NOT add explanations
- sentiment must be: "positive", "neutral", "negative", or "ambivalent"
- score must be between -1 and 1
- confidence must be between 0 and 1
- Analyze OVERALL sentiment only (question-level calculated separately)`;
  }

  private createQuoteExtractionPrompt(responses: ResponseDocument[], form: Form): string {
    const responsesData = responses.map((r) => ({
      responseId: (r._id as Types.ObjectId).toString(),
      answers: r.answers.map(ans => {
        const question = form.questions.find(q => q.id === ans.questionId);
        return { questionId: ans.questionId, questionTitle: question?.title, value: ans.value };
      })
    }));

    return `CRITICAL: You MUST return ONLY valid JSON. No explanations, no markdown, no prose.

Task: Select representative quotes from ${responses.length} survey responses.

Responses:
${JSON.stringify(responsesData, null, 2)}

REQUIRED OUTPUT FORMAT (valid JSON object with "results" array):
{
  "results": [{
    "responseId": "string",
    "quotes": [
      {
        "text": "exact quote text",
        "questionId": "string",
        "representativeness": 0.8,
        "impact": 0.7,
        "themes": ["theme1", "theme2"]
      }
    ],
    "responseQuality": {
      "completeness": 0.9,
      "depth": 0.7,
      "clarity": 0.8
    }
  }]
}

RULES:
- Output MUST be valid JSON object (test with JSON.parse)
- Root must be an object with "results" array
- Do NOT include any text before or after the JSON
- Do NOT use markdown code blocks
- Do NOT add explanations
- All numeric values (representativeness, impact, completeness, depth, clarity) must be between 0 and 1
- text must be exact quote from responses
- themes must be array of strings
- quotes can be empty array [] if no representative quotes found`;
  }

  private async saveChunkResults(waveResults: any[]): Promise<void> {
    // Collect all updates before executing them
    const updates: any[] = [];

    for (const chunkResult of waveResults) {
      const { topics, sentiment, quotes } = chunkResult;

      // Verify structure
      if (!Array.isArray(topics) || !Array.isArray(sentiment) || !Array.isArray(quotes)) {
        console.error('[saveChunkResults] Invalid structure:', { 
          topicsIsArray: Array.isArray(topics), 
          sentimentIsArray: Array.isArray(sentiment), 
          quotesIsArray: Array.isArray(quotes) 
        });
        continue;
      }

      // Create lookup maps for flexible matching (some responses may not have quotes)
      const topicsMap = new Map(topics.map(t => [t.responseId, t]));
      const sentimentMap = new Map(sentiment.map(s => [s.responseId, s]));
      const quotesMap = new Map(quotes.map(q => [q.responseId, q]));

      // Get all unique response IDs (union of all three)
      const allResponseIds = new Set([
        ...topics.map(t => t.responseId),
        ...sentiment.map(s => s.responseId),
        ...quotes.map(q => q.responseId)
      ]);

      console.log(`[saveChunkResults] Processing ${allResponseIds.size} unique responses from chunk:`, {
        topicsLength: topics.length,
        sentimentLength: sentiment.length,
        quotesLength: quotes.length,
        uniqueResponses: allResponseIds.size
      });

      for (const responseId of allResponseIds) {
        const topicData = topicsMap.get(responseId);
        const sentimentData = sentimentMap.get(responseId);
        const quoteData = quotesMap.get(responseId);

        if (!topicData && !sentimentData && !quoteData) {
          console.warn(`[saveChunkResults] No data for response ${responseId}`);
          continue;
        }

        // Build update object with available data
        const updateFields: any = {
          'metadata.lastAnalyzed': new Date()
        };

        if (topicData?.topics) {
          updateFields['metadata.allTopics'] = topicData.topics.map((t: any) => t.topic) || [];
          updateFields['metadata.primaryTopics'] = topicData.topics.filter((t: any) => t.isPrimary).map((t: any) => t.topic) || [];
          updateFields['metadata.topicDetails'] = topicData.topics || [];
        }

        if (sentimentData?.overallSentiment) {
          updateFields['metadata.overallSentiment'] = {
            label: sentimentData.overallSentiment.sentiment,
            score: sentimentData.overallSentiment.score,
            emotionalTone: sentimentData.overallSentiment.emotionalTone,
            confidence: sentimentData.overallSentiment.confidence,
            reasoning: sentimentData.overallSentiment.reasoning
          };
        }

        if (quoteData) {
          // Calculate overall representativeness from quote scores
          const quotesArray = quoteData.quotes || [];
          let representativeness: 'typical' | 'deviant' | 'mixed' = 'typical';
          
          if (quotesArray.length > 0) {
            const avgRepresentativeness = quotesArray.reduce((sum: number, q: any) => sum + (q.representativeness || 0), 0) / quotesArray.length;
            if (avgRepresentativeness < 0.4) {
              representativeness = 'deviant';
            } else if (avgRepresentativeness >= 0.4 && avgRepresentativeness < 0.7) {
              representativeness = 'mixed';
            } else {
              representativeness = 'typical';
            }
          }

          // Convert depth score to label
          let depthLabel: 'superficial' | 'moderate' | 'deep' = 'moderate';
          if (quoteData.responseQuality?.depth) {
            if (quoteData.responseQuality.depth < 0.4) {
              depthLabel = 'superficial';
            } else if (quoteData.responseQuality.depth >= 0.7) {
              depthLabel = 'deep';
            }
          }

          // Store quotes in schema-compliant format
          updateFields['metadata.quotes'] = {
            keyQuotes: quotesArray.map((q: any) => ({
              quote: q.text || '',
              significance: q.themes?.join(', ') || '',
              questionId: q.questionId || '',
              relatedTopics: q.themes || []
            })),
            representativeness: representativeness,
            responseQuality: {
              depth: depthLabel,
              completeness: quoteData.responseQuality?.completeness || 0.5,
              coherence: quoteData.responseQuality?.clarity || 0.5
            }
          };
        } else {
          // No quote data - set default structure
          updateFields['metadata.quotes'] = {
            keyQuotes: [],
            representativeness: 'typical',
            responseQuality: {
              depth: 'moderate',
              completeness: 0.5,
              coherence: 0.5
            }
          };
        }

        updates.push({
          filter: { _id: responseId },
          update: { $set: updateFields }
        });
      }
    }

    // Execute all updates
    console.log(`[saveChunkResults] Executing ${updates.length} updates...`);
    for (const { filter, update } of updates) {
      try {
        const result = await this.responseModel.updateOne(filter, update).exec();
        if (result.matchedCount === 0) {
          console.warn(`[saveChunkResults] No document matched for responseId: ${filter._id}`);
        }
      } catch (error) {
        console.error(`[saveChunkResults] Error updating responseId ${filter._id}:`, error);
      }
    }
    console.log(`[saveChunkResults] Completed ${updates.length} updates`);
  }

  /**
   * PHASE 2: Cluster all extracted topics into canonical categories and store on each response
   * This makes aggregation trivial - just count canonical topics across responses
   */
  private async clusterAndStoreCanonicalTopics(
    formId: Types.ObjectId,
    taskId: string,
    progressCallback: (update: any) => void
  ): Promise<void> {
    console.log(`[Analytics][${taskId}] Starting canonical topic clustering`);

    // Get all processed responses with topics
    const responsesWithTopics = await this.responseModel.find({
      formId: formId,
      'metadata.processingTaskId': taskId,
      'metadata.allTopics': { $exists: true, $ne: [] }
    }).exec();

    if (responsesWithTopics.length === 0) {
      console.log(`[Analytics][${taskId}] No responses with topics to cluster`);
      return;
    }

    // Collect all unique raw topics across all responses
    const allRawTopics = new Set<string>();
    responsesWithTopics.forEach(response => {
      if (Array.isArray(response.metadata.allTopics)) {
        response.metadata.allTopics.forEach(topic => allRawTopics.add(topic));
      }
    });

    const uniqueTopics = Array.from(allRawTopics);
    console.log(`[Analytics][${taskId}] Found ${uniqueTopics.length} unique raw topics to cluster`);

    progressCallback({
      type: 'progress',
      message: `Clustering ${uniqueTopics.length} unique topics into canonical categories...`,
      progress: 47,
      taskId
    });

    // Use LLM to create canonical topic mapping
    const canonicalMapping = await this.createCanonicalTopicMapping(uniqueTopics);
    console.log(`[Analytics][${taskId}] Created ${Object.keys(canonicalMapping).length} canonical topic mappings`);

    progressCallback({
      type: 'progress',
      message: 'Storing canonical topics on responses...',
      progress: 50,
      taskId
    });

    // Update each response with canonical topics
    const updates: any[] = [];
    for (const response of responsesWithTopics) {
      const rawTopics = response.metadata.allTopics || [];
      const canonicalTopics = rawTopics
        .map(rawTopic => canonicalMapping[rawTopic] || rawTopic) // Map to canonical or keep original
        .filter((value, index, self) => self.indexOf(value) === index); // Remove duplicates

      updates.push({
        filter: { _id: response._id },
        update: {
          $set: {
            'metadata.canonicalTopics': canonicalTopics,
            'metadata.topicMapping': canonicalMapping
          }
        }
      });
    }

    // Execute updates in batches
    console.log(`[Analytics][${taskId}] Updating ${updates.length} responses with canonical topics`);
    for (const { filter, update } of updates) {
      await this.responseModel.updateOne(filter, update).exec();
    }

    console.log(`[Analytics][${taskId}] Canonical topic clustering complete`);
  }

  /**
   * Create canonical topic mapping using LLM
   * Maps each raw topic to its canonical category
   */
  private async createCanonicalTopicMapping(rawTopics: string[]): Promise<Record<string, string>> {
    if (rawTopics.length === 0) return {};

    const prompt = `You are a topic clustering expert. Map each raw topic to a canonical category name.
Topics may be similar but phrased differently (e.g., "Web Dev", "web development", "building websites"  "Web Development").
Topics in different languages with same meaning should map to same canonical name.

Raw topics to cluster:
${JSON.stringify(rawTopics, null, 2)}

REQUIRED OUTPUT FORMAT (valid JSON object):
{
  "mapping": {
    "raw topic 1": "Canonical Category 1",
    "raw topic 2": "Canonical Category 1",
    "raw topic 3": "Canonical Category 2",
    ...
  }
}

RULES:
- Output MUST be valid JSON object with "mapping" property
- Each raw topic MUST appear exactly once as a key in mapping
- Canonical names should be clear, concise, title-cased
- Group semantically similar topics under same canonical name
- Preserve language diversity but use English for canonical names
- Do NOT add explanations, only return JSON`;

    const resultRaw = await this.aiService['invokeModelRaw'](prompt);
    try {
      const result = JSON.parse(resultRaw);
      return result.mapping || {};
    } catch (e) {
      console.error('[createCanonicalTopicMapping] Failed to parse LLM result:', e);
      // Fallback: identity mapping (each topic maps to itself)
      return rawTopics.reduce((acc, topic) => {
        acc[topic] = topic;
        return acc;
      }, {} as Record<string, string>);
    }
  }

  private async releaseTaskClaim(taskId: string, formId: Types.ObjectId): Promise<void> {
    await this.responseModel.updateMany(
      { formId: formId, 'metadata.processingTaskId': taskId },
      {
        $set: { 'metadata.processedForAnalytics': true, 'metadata.lastAnalyzed': new Date() },
        $unset: { 'metadata.processingTaskId': '', 'metadata.processingStartedAt': '' }
      }
    ).exec();
  }

  private determineTheoreticalSampling(responses: ResponseDocument[], form: Form): SamplingStrategy {
    const strategy: SamplingStrategy = {
      description: '',
      rationale: '',
      criteria: [],
    };

    if (responses.length <= 50) {
      strategy.description = 'Complete sample';
      strategy.rationale = 'Small dataset allows complete analysis';
      strategy.criteria = ['all'];
    } else {
      strategy.description = 'Theoretical sampling with maximum variation';
      strategy.rationale = 'Ensure diverse perspectives and saturation of themes';
      strategy.criteria = [
        'maximum_variation',
        'deviant_cases',
        'typical_cases',
        'extreme_cases',
        'information_rich',
        'temporal_coverage',
      ];
    }

    return strategy;
  }

  private theoreticalSample(responses: ResponseDocument[], strategy: SamplingStrategy): ResponseDocument[] {
    if (strategy.criteria.includes('all')) {
      return responses;
    }

    const targetSize = Math.min(
      Math.max(50, Math.ceil(Math.sqrt(responses.length) * 10)),
      200
    );

    // For now, simple stratified sampling - can enhance with actual theoretical sampling
    const recent = responses.slice(0, Math.floor(targetSize * 0.3));
    const oldest = responses.slice(-Math.floor(targetSize * 0.2));
    const random = responses
      .sort(() => Math.random() - 0.5)
      .slice(0, Math.floor(targetSize * 0.5));

    return [...new Set([...recent, ...oldest, ...random])].slice(0, targetSize);
  }

  private calculateTopicFrequencies(responses: ResponseDocument[]): Record<string, any> {
    const frequency: Record<string, { count: number; percentage: number; associatedQuestions: string[]; sentimentBreakdown: { positive: number; neutral: number; negative: number } }> = {};

    responses.forEach(r => {
      // Use canonicalTopics if available, otherwise fall back to allTopics
      const topics = r.metadata.canonicalTopics || r.metadata.allTopics || [];
      
      // Track unique topics per response (don't count duplicates within same response)
      const uniqueTopics = new Set(topics);
      
      uniqueTopics.forEach(topic => {
        if (!frequency[topic]) {
          frequency[topic] = {
            count: 0,
            percentage: 0,
            associatedQuestions: [],
            sentimentBreakdown: { positive: 0, neutral: 0, negative: 0 },
          };
        }
        frequency[topic].count++;

        // Track sentiment
        if (r.metadata.overallSentiment) {
          const sentiment = r.metadata.overallSentiment.label;
          if (sentiment === 'positive') frequency[topic].sentimentBreakdown.positive++;
          else if (sentiment === 'negative') frequency[topic].sentimentBreakdown.negative++;
          else frequency[topic].sentimentBreakdown.neutral++;
        }
      });
    });

    // Calculate percentages
    Object.keys(frequency).forEach(topic => {
      frequency[topic].percentage = Math.round((frequency[topic].count / responses.length) * 100);
    });

    return frequency;
  }

  private calculateSentimentDistribution(responses: ResponseDocument[]): any {
    const counts = { positive: 0, neutral: 0, negative: 0 };
    let totalScore = 0;

    responses.forEach(r => {
      if (r.metadata.overallSentiment) {
        const label = r.metadata.overallSentiment.label;
        if (label === 'positive') counts.positive++;
        else if (label === 'negative') counts.negative++;
        else counts.neutral++;
        totalScore += r.metadata.overallSentiment.score;
      }
    });

    const total = responses.length;
    return {
      positive: Math.round((counts.positive / total) * 100),
      neutral: Math.round((counts.neutral / total) * 100),
      negative: Math.round((counts.negative / total) * 100),
      averageScore: totalScore / total,
    };
  }

  private assessDataQuality(responses: ResponseDocument[]): any {
    let totalQuality = 0;
    let count = 0;

    responses.forEach(r => {
      if (r.metadata.quotes?.responseQuality) {
        totalQuality += r.metadata.quotes.responseQuality.completeness;
        count++;
      }
    });

    return {
      overallScore: count > 0 ? totalQuality / count : 0.5,
    };
  }

  /**
   * Generate aggregate insights with progress updates
   */
  private async generateAggregateInsightsWithProgress(
    form: FormDocument,
    responses: ResponseDocument[],
    sample: ResponseDocument[],
    statistics: any,
    progressCallback: (update: any) => void,
    taskId?: string
  ): Promise<void> {
    // Stage 1: Calculate topic distribution from canonical topics (already stored on responses)
    if (taskId) {
      this.updateTaskProgress(taskId, 60, 'Analyzing topic distribution...');
    }
    progressCallback({ 
      type: 'progress', 
      message: 'Analyzing topic distribution...', 
      progress: 60,
      taskId,
      stats: {
        stage: 'Aggregate Analysis: Topic Distribution',
        processedResponses: responses.length,
        totalResponses: responses.length
      }
    });
    
    // Use statistics.topicFrequencies which already reads from canonical topics
    const topicFrequencies = statistics.topicFrequencies;
    
    if (taskId) {
      this.updateTaskProgress(taskId, 65, 'Sorting top topics...');
    }
    progressCallback({ 
      type: 'progress', 
      message: 'Sorting top topics...', 
      progress: 70,
      taskId,
      stats: {
        stage: 'Aggregate Analysis: Topic Sorting',
        processedResponses: responses.length,
        totalResponses: responses.length,
        uniqueTopics: Object.keys(topicFrequencies).length
      }
    });
    
    const topTopics = Object.entries(topicFrequencies)
      .sort(([, a]: any, [, b]: any) => b.count - a.count)
      .slice(0, 15) // Show top 15 topics
      .map(([topic]) => topic);

    if (taskId) {
      this.updateTaskProgress(taskId, 80, 'Computing sentiment metrics...');
    }
    progressCallback({ 
      type: 'progress', 
      message: 'Computing sentiment metrics...', 
      progress: 80,
      taskId,
      stats: {
        stage: 'Aggregate Analysis: Sentiment Metrics',
        processedResponses: responses.length,
        totalResponses: responses.length
      }
    });

    if (taskId) {
      this.updateTaskProgress(taskId, 85, 'Collecting quotes and insights...');
    }
    progressCallback({ 
      type: 'progress', 
      message: 'Collecting quotes and insights...', 
      progress: 85,
      taskId
    });

    // Collect all quotes from responses and transform to schema format
    const allQuotes: Array<{
      text: string;
      responseId: string;
      submittedAt: Date;
      topics: string[];
      sentiment: string;
      emotionalTone: string;
      representativeness: number;
      impact: number;
      depth: string;
    }> = [];
    
    responses.forEach(r => {
      if (r.metadata?.quotes && Array.isArray(r.metadata.quotes)) {
        r.metadata.quotes.forEach((quote: any) => {
          allQuotes.push({
            text: quote.text || '',
            responseId: (r._id as Types.ObjectId).toString(),
            submittedAt: r.submittedAt || new Date(),
            topics: quote.themes || [],
            sentiment: r.metadata?.overallSentiment?.label || 'neutral',
            emotionalTone: r.metadata?.overallSentiment?.emotionalTone || 'neutral',
            representativeness: quote.representativeness || 0.5,
            impact: quote.impact || 0.5,
            depth: 'moderate' // Will be enhanced with actual quality metrics later
          });
        });
      }
    });

    // Sort quotes by representativeness and quality
    const sortedQuotes = allQuotes.sort((a, b) => {
      const scoreA = (a.representativeness || 0) * 0.6 + (a.impact || 0) * 0.4;
      const scoreB = (b.representativeness || 0) * 0.6 + (b.impact || 0) * 0.4;
      return scoreB - scoreA;
    });

    const representativeQuotes = sortedQuotes.slice(0, 10).map(q => ({
      text: q.text,
      responseId: q.responseId,
      submittedAt: q.submittedAt,
      topics: q.topics,
      sentiment: q.sentiment,
      emotionalTone: q.emotionalTone,
      representativeness: 'typical' as const,
      depth: (q.depth === 'deep' || q.depth === 'moderate' || q.depth === 'superficial') 
        ? q.depth as 'superficial' | 'moderate' | 'deep'
        : 'moderate' as const
    }));

    const highQualityQuotes = allQuotes
      .filter(q => (q.impact || 0) > 0.7)
      .slice(0, 5)
      .map(q => ({
        text: q.text,
        responseId: q.responseId,
        submittedAt: q.submittedAt,
        topics: q.topics,
        sentiment: q.sentiment,
        emotionalTone: q.emotionalTone,
        representativeness: 'typical' as const,
        depth: 'deep' as const
      }));

    // Collect emotional tones
    const emotionalTones = responses
      .map(r => r.metadata?.overallSentiment?.emotionalTone)
      .filter((tone): tone is string => typeof tone === 'string');
    const toneCounts = emotionalTones.reduce((acc, tone) => {
      acc[tone] = (acc[tone] || 0) + 1;
      return acc;
    }, {} as Record<string, number>);
    const totalTones = emotionalTones.length;
    const dominantEmotionalTones = Object.entries(toneCounts)
      .sort(([, a], [, b]) => b - a)
      .slice(0, 5)
      .map(([tone, count]) => ({
        tone,
        percentage: Math.round((count / totalTones) * 100),
        contexts: [] // Could be populated with question IDs where this tone appears
      }));

    if (taskId) {
      this.updateTaskProgress(taskId, 90, 'Building analytics summary...');
    }
    progressCallback({ 
      type: 'progress', 
      message: 'Building analytics summary...', 
      progress: 90,
      taskId,
      stats: {
        stage: 'Aggregate Analysis: Finalizing',
        processedResponses: responses.length,
        totalResponses: responses.length
      }
    });

    // Generate key findings based on data
    const keyFindings: Array<{
      finding: string;
      evidence: {
        correlation?: number;
        significance?: number;
        supportingQuotes: string[];
        pattern: string;
      };
      confidence: 'high' | 'medium' | 'low';
      basedOnResponses: number;
      importance?: 'high' | 'medium' | 'low';
    }> = [];
    
    const sentiment = statistics.sentimentDistribution;
    
    // Finding 1: Top topics
    if (topTopics.length > 0) {
      const topTopic = topTopics[0];
      const topicData = topicFrequencies[topTopic];
      keyFindings.push({
        finding: `Most discussed topic: "${topTopic}" (mentioned in ${topicData.percentage}% of responses)`,
        evidence: {
          supportingQuotes: representativeQuotes.filter(q => q.topics?.includes(topTopic)).slice(0, 3).map(q => q.text),
          pattern: `Mentioned ${topicData.count} times across ${responses.length} responses`
        },
        confidence: topicData.count > responses.length * 0.3 ? 'high' : 'medium',
        basedOnResponses: topicData.count,
        importance: 'high'
      });
    }

    // Finding 2: Sentiment overview
    const dominantSentiment = sentiment.positive > sentiment.negative ? 'positive' : 
                               sentiment.negative > sentiment.positive ? 'negative' : 'neutral';
    keyFindings.push({
      finding: `Overall sentiment is ${dominantSentiment} (${sentiment.positive}% positive, ${sentiment.neutral}% neutral, ${sentiment.negative}% negative)`,
      evidence: {
        supportingQuotes: representativeQuotes.slice(0, 3).map(q => q.text),
        pattern: `Sentiment distribution across ${responses.length} responses`,
        significance: Math.abs(sentiment.positive - sentiment.negative) / 100
      },
      confidence: 'high',
      basedOnResponses: responses.length,
      importance: sentiment.negative > 30 ? 'high' : 'medium'
    });

    // Finding 3: Emotional tone
    if (dominantEmotionalTones.length > 0) {
      const topTones = dominantEmotionalTones.slice(0, 3).map(t => `${t.tone} (${t.percentage}%)`).join(', ');
      keyFindings.push({
        finding: `Dominant emotional tones: ${topTones}`,
        evidence: {
          supportingQuotes: [],
          pattern: `Emotional tone distribution across ${responses.length} responses`
        },
        confidence: 'medium',
        basedOnResponses: responses.length
      });
    }

    // Finding 4: Response quality
    const avgQuality = statistics.dataQuality.overallScore;
    keyFindings.push({
      finding: `Average response quality: ${(avgQuality * 100).toFixed(0)}%`,
      evidence: {
        supportingQuotes: [],
        pattern: `Quality metrics: completeness, depth, and clarity averaged across responses`
      },
      confidence: 'high',
      basedOnResponses: responses.length,
      importance: avgQuality < 0.6 ? 'high' : 'medium'
    });

    // Generate recommendations
    const recommendations: Array<{
      recommendation: string;
      priority: 'urgent' | 'important' | 'maintain';
      basedOn: string;
      suggestedAction: string;
      expectedImpact: string;
      confidence: 'high' | 'medium' | 'low';
    }> = [];
    
    if (sentiment.negative > 30) {
      recommendations.push({
        recommendation: 'Address high negative sentiment',
        priority: 'urgent',
        basedOn: `${sentiment.negative}% of responses show negative sentiment`,
        suggestedAction: 'Review negative feedback and identify common pain points for immediate action',
        expectedImpact: 'Improved satisfaction and reduced churn',
        confidence: 'high'
      });
    }
    
    // Only suggest consolidation if there are significantly more topics (8+)
    if (topTopics.length >= 8) {
      const targetThemes = topTopics.length >= 15 ? '3-5' : topTopics.length >= 10 ? '4-6' : '5-7';
      recommendations.push({
        recommendation: 'Consolidate diverse topics into themes',
        priority: 'important',
        basedOn: `${topTopics.length} distinct topics identified`,
        suggestedAction: `Group related topics into ${targetThemes} main themes for focused analysis`,
        expectedImpact: 'Clearer insights and actionable patterns',
        confidence: 'medium'
      });
    }

    if (avgQuality < 0.6) {
      recommendations.push({
        recommendation: 'Improve question design for richer responses',
        priority: 'important',
        basedOn: `Average response quality is ${(avgQuality * 100).toFixed(0)}%`,
        suggestedAction: 'Revise questions to be more specific and engaging',
        expectedImpact: 'Higher quality data for better decision-making',
        confidence: 'high'
      });
    }
    
    if (sentiment.positive > 70) {
      recommendations.push({
        recommendation: 'Maintain current approach',
        priority: 'maintain',
        basedOn: `${sentiment.positive}% positive sentiment indicates high satisfaction`,
        suggestedAction: 'Continue current practices and monitor for consistency',
        expectedImpact: 'Sustained positive feedback',
        confidence: 'high'
      });
    }

    // Calculate topic correlations
    const topicCooccurrences = this.calculateTopicCooccurrence(responses);
    const topicSentimentCorrelations = this.calculateTopicSentimentCorrelation(responses);
    const closedQuestionTopicCorrelations = this.calculateClosedQuestionTopicCorrelations(form, responses);

    form.analytics = {
      lastUpdated: new Date(),
      totalResponsesAnalyzed: responses.length,
      cacheVersion: 1,
      // Note: canonicalTopics are embedded in the distribution field keys
      topics: {
        distribution: topicFrequencies,
        topTopics,
        dominantThemes: topTopics.slice(0, 3).map(theme => {
          const topicData = topicFrequencies[theme];
          return {
            theme,
            frequency: topicData.count,
            sentiment: topicData.sentimentBreakdown,
            representativeQuotes: representativeQuotes
              .filter(q => q.topics.includes(theme))
              .slice(0, 3)
              .map(q => q.text),
            relatedQuestions: topicData.associatedQuestions
          };
        }),
        emergingThemes: topTopics.slice(3, 6).map(theme => {
          const topicData = topicFrequencies[theme];
          return {
            theme,
            frequency: topicData.count,
            trend: 'rare' as const, // Would need temporal data to detect 'growing'
            sentiment: topicData.sentimentBreakdown,
            representativeQuotes: representativeQuotes
              .filter(q => q.topics.includes(theme))
              .slice(0, 2)
              .map(q => q.text)
          };
        }),
        counterNarratives: [],
        cooccurrence: topicCooccurrences,
      },
      
      sentiment: {
        overall: statistics.sentimentDistribution,
        byQuestion: {},
        emotionalTones: dominantEmotionalTones,
        dominantTags: topTopics.slice(0, 5),
        topicCorrelations: topicSentimentCorrelations,
      },

      correlations: {
        byQuestion: {},
        questionPairs: [],
        topCorrelations: [],
        closedQuestionTopics: closedQuestionTopicCorrelations,
      },
      
      quotes: {
        representative: representativeQuotes,
        highQuality: highQualityQuotes,
        deviant: [],
      },
      
      deviantCases: [],
      
      insights: {
        summary: '', // Will be generated in next step
        keyFindings,
        recommendations,
      },
      
      // Climate data for Overall Response Climate Card
      climate: this.calculateClimateData(responses, topTopics, sentiment, dominantEmotionalTones),
    };

    // FINAL STAGE: Generate comprehensive summary using LLM
    if (taskId) {
      this.updateTaskProgress(taskId, 90, 'Generating comprehensive analysis summary...');
    }
    progressCallback({ type: 'progress', message: 'Generating comprehensive analysis summary...', progress: 90, taskId });

    // Ensure analytics object and nested structures exist
    if (!form.analytics) {
      form.analytics = {} as any;
    }
    const analytics = form.analytics!;
    if (!analytics.insights) {
      analytics.insights = {} as any;
    }
    
    analytics.insights.summary = await this.generateAnalyticsSummary(
      form,
      responses,
      topTopics,
      sentiment,
      keyFindings,
      recommendations,
      representativeQuotes.slice(0, 5),
      closedQuestionTopicCorrelations
    );

    progressCallback({ type: 'progress', message: 'Saving analytics...', progress: 95 });

    await form.save();
  }
  
  /**
   * Calculate climate data with semantic axis based on topics and sentiment
   */
  private calculateClimateData(
    responses: ResponseDocument[],
    topTopics: string[],
    sentimentDistribution: any,
    emotionalTones: Array<{ tone: string; percentage: number }>
  ): any {
    const total = responses.length;
    const positivityScore = Math.round(
      ((sentimentDistribution.positive + sentimentDistribution.neutral * 0.5) / 100) * 100
    );
    
    // Determine dominant tendency
    const tendencyValue = (sentimentDistribution.positive - sentimentDistribution.negative) / 100;
    const dominantTendency = tendencyValue > 0.2 ? 'positive' : tendencyValue < -0.2 ? 'negative' : 'neutral';
    
    // Create semantic axis from top topics and emotional tones
    let semanticAxis: { left: string; right: string; position: number } | undefined;
    
    if (topTopics.length >= 2 && emotionalTones.length >= 2) {
      // Use dominant emotional tones to create a semantic axis
      const leftTone = emotionalTones[0]?.tone || 'concerned';
      const rightTone = emotionalTones.length > 1 ? emotionalTones[1]?.tone : 'satisfied';
      
      semanticAxis = {
        left: leftTone,
        right: rightTone,
        position: (tendencyValue + 1) / 2 // Normalize -1..1 to 0..1
      };
    } else if (topTopics.length >= 2) {
      // Fallback to topics if not enough emotional tones
      semanticAxis = {
        left: topTopics[0] || 'developer',
        right: topTopics[1] || 'programmer',
        position: (tendencyValue + 1) / 2
      };
    }
    
    return {
      positivityScore,
      sentimentBreakdown: {
        positive: sentimentDistribution.positive,
        neutral: sentimentDistribution.neutral,
        negative: sentimentDistribution.negative
      },
      dominantTendency,
      semanticAxis
    };
  }

  /**
   * Reprocess a single response to regenerate its analytics metadata
   */
  async reprocessSingleResponse(formId: string, responseId: string): Promise<any> {
    const form = await this.formModel.findById(formId).exec();
    if (!form) {
      throw new Error('Form not found');
    }

    const response = await this.responseModel.findOne({
      _id: new Types.ObjectId(responseId),
      formId: new Types.ObjectId(formId),
    }).exec();

    if (!response) {
      throw new Error('Response not found');
    }

    if (!response.metadata.hasTextContent) {
      return {
        success: false,
        message: 'Response has no text content to analyze',
        responseId,
      };
    }

    // Reset metadata to reprocess
    response.metadata.processedForAnalytics = false;
    response.metadata.topics = undefined;
    response.metadata.sentiment = undefined;
    response.metadata.discourse = undefined;
    response.metadata.quotes = undefined;
    response.metadata.extractedKeywords = [];
    await form.save();
  }

  /**
   * Reprocess all responses to regenerate their analytics metadata
   */
  async reprocessAllResponses(formId: string, onlyFailed: boolean = false): Promise<any> {
    const form = await this.formModel.findById(formId).exec();
    if (!form) {
      throw new Error('Form not found');
    }

    const query: any = {
      formId: new Types.ObjectId(formId),
    };

    if (onlyFailed) {
      // Only reprocess responses that were never processed or failed
      query['metadata.processedForAnalytics'] = { $ne: true };
    }

    const responses = await this.responseModel.find(query).exec();

    if (responses.length === 0) {
      return {
        success: true,
        message: 'No responses to reprocess',
        totalReprocessed: 0,
      };
    }

    // Filter to only responses that have text content
    const responsesWithText = responses.filter(response => {
      return response.answers.some(answer => 
        answer.value && typeof answer.value === 'string' && answer.value.trim().length > 0
      );
    });

    if (responsesWithText.length === 0) {
      return {
        success: true,
        message: 'No responses with text content to reprocess',
        totalReprocessed: 0,
      };
    }

    console.log(`[Analytics] Marking ${responsesWithText.length} responses for reprocessing...`);

    // Just reset metadata flags - don't actually process yet
    // The actual processing will happen during analytics generation
    const updateResult = await this.responseModel.updateMany(
      { _id: { $in: responsesWithText.map(r => r._id) } },
      {
        $set: {
          'metadata.processedForAnalytics': false,
          'metadata.hasTextContent': true,
        },
        $unset: {
          'metadata.topics': '',
          'metadata.sentiment': '',
          'metadata.discourse': '',
          'metadata.quotes': '',
          'metadata.allTopics': '',
          'metadata.overallSentiment': '',
          'metadata.lastAnalyzed': '',
        }
      }
    ).exec();

    console.log(`[Analytics] Marked ${updateResult.modifiedCount} responses as unprocessed`);

    return {
      success: true,
      message: `Marked ${responsesWithText.length} responses for reprocessing`,
      totalReprocessed: responsesWithText.length,
      modifiedCount: updateResult.modifiedCount,
      onlyFailed,
    };
  }

  /**
   * Generate concise analytics summary with citations from important responses
   * This provides a brief narrative overview (3-5 sentences) with direct quotes
   */
  private async generateAnalyticsSummary(
    form: FormDocument,
    responses: ResponseDocument[],
    topTopics: string[],
    sentimentDistribution: any,
    keyFindings: any[],
    recommendations: any[],
    highlightedQuotes: any[],
    closedQuestionCorrelations: any[]
  ): Promise<string> {
    try {
      // Find responses related to most common topics for citations
      const topicToResponses = new Map<string, ResponseDocument[]>();
      
      // Group responses by their most common topics
      for (const response of responses) {
        const responseTopics = response.metadata?.allTopics || [];
        for (const topic of responseTopics.slice(0, 3)) { // Top 3 topics per response
          if (topTopics.includes(topic)) {
            if (!topicToResponses.has(topic)) {
              topicToResponses.set(topic, []);
            }
            const topicResponses = topicToResponses.get(topic);
            if (topicResponses) {
              topicResponses.push(response);
            }
          }
        }
      }

      // Get representative quotes for top 3 topics with highest response counts
      const topicQuotes = topTopics.slice(0, 3).map(topic => {
        const relatedResponses = topicToResponses.get(topic) || [];
        if (relatedResponses.length > 0) {
          // Get a quote from the first related response
          const response = relatedResponses[0];
          const quote = response.metadata?.quotes?.keyQuotes?.[0];
          return quote ? { 
            topic, 
            quote: quote.quote, 
            count: relatedResponses.length 
          } : null;
        }
        return null;
      }).filter(Boolean);

      const formContext = {
        title: form.title,
        description: form.description || 'No description provided',
        totalQuestions: form.questions.length,
      };

      // Calculate closed question statistics
      const closedQuestions = form.questions.filter(q => 
        ['dropdown', 'radio', 'checkbox'].includes(q.type)
      );
      
      const closedQuestionStats = closedQuestions.map(q => {
        const answerCounts = new Map<string, number>();
        responses.forEach(r => {
          const answer = r.answers.find(a => a.questionId === q.id);
          if (answer?.value) {
            const values = Array.isArray(answer.value) ? answer.value : [answer.value];
            values.forEach(v => {
              const valStr = String(v);
              answerCounts.set(valStr, (answerCounts.get(valStr) || 0) + 1);
            });
          }
        });
        
        const sortedAnswers = Array.from(answerCounts.entries())
          .sort((a, b) => b[1] - a[1])
          .slice(0, 3); // Top 3 answers
        
        return {
          question: q.title,
          topAnswers: sortedAnswers.map(([value, count]) => ({
            value,
            count,
            percentage: Math.round((count / responses.length) * 100)
          }))
        };
      });

      // Format insights from closed question topic correlations
      const closedQuestionInsights = closedQuestionCorrelations
        .slice(0, 2) // Top 2 questions
        .map(qc => {
          const topCorrelation = qc.correlations[0]; // Most common answer
          if (!topCorrelation) return null;
          
          const topTopic = topCorrelation.topicDistribution[0];
          if (!topTopic) return null;
          
          return {
            question: qc.questionTitle,
            answer: topCorrelation.answerValue,
            count: topCorrelation.responseCount,
            topTopic: topTopic.topic,
            topicPercentage: topTopic.percentage
          };
        })
        .filter(Boolean);

      const analyticsContext = {
        responseCount: responses.length,
        topTopics: topTopics.slice(0, 3),
        sentiment: {
          positive: sentimentDistribution.positive,
          neutral: sentimentDistribution.neutral,
          negative: sentimentDistribution.negative,
        },
        topicQuotes,
        keyInsight: keyFindings[0]?.finding || null,
        closedQuestions: closedQuestionStats,
        closedQuestionInsights
      };

      const prompt = `You are a professional data analyst writing an executive summary of survey analytics.

FORM CONTEXT (for understanding direction, do NOT repeat in summary):
- Title: "${formContext.title}"
- Description: "${formContext.description}"
- Questions: ${formContext.totalQuestions} questions

ANALYSIS RESULTS:
- Total responses: ${analyticsContext.responseCount}
- Main topics discussed: ${analyticsContext.topTopics.join(', ')}
- Sentiment: ${analyticsContext.sentiment.positive}% positive, ${analyticsContext.sentiment.neutral}% neutral, ${analyticsContext.sentiment.negative}% negative

${analyticsContext.closedQuestions.length > 0 ? `CLOSED QUESTION RESPONSES:
${analyticsContext.closedQuestions.map((d: any) => 
  `${d.question}: ${d.topAnswers.map((a: any) => `${a.value} (${a.percentage}%)`).join(', ')}`
).join('\n')}` : ''}

${analyticsContext.closedQuestionInsights.length > 0 ? `TOPIC PATTERNS BY RESPONSE:
${analyticsContext.closedQuestionInsights.map((di: any) => 
  ` ${di.answer} (${di.count} responses) primarily discuss ${di.topTopic} (${di.topicPercentage}% of their topics)`
).join('\n')}` : ''}

Sample responses from top topics:
${analyticsContext.topicQuotes.map((tq: any) => ` ${tq.topic} (${tq.count} responses): "${tq.quote}"`).join('\n')}

TASK:
Write a professional, structured executive summary using this exact format:

**FORMAT TEMPLATE:**
[Opening paragraph: 2-3 sentences providing overview of what respondents revealed in relation to the form's purpose. Include 1 direct citation with quotation marks to illustrate the main theme. Use **bold** for key metrics or emphasis. Consider mentioning key response patterns if significant.]

**Key Takeaways:**
- [First main finding - clear, actionable insight, may reference response patterns]
- [Second main finding - include citation if relevant: "quote"]
- [Third main finding - emphasize with **bold** if important, may reference response segmentation]

**REQUIREMENTS:**
1. Opening paragraph:
   - Focus on outcomes and what respondents revealed (NOT describing the survey)
   - Mention overall sentiment (e.g., "Sentiment is **strongly positive** (${analyticsContext.sentiment.positive}%)")
   - Include 1 direct citation with quotation marks to make it respondent-oriented
   - Use **bold** for key numbers or emphasis
   - Optionally mention response patterns if they provide valuable context

2. Key Takeaways (3 bullet points):
   - Each takeaway should be clear, concise, and actionable
   - Include citations where relevant to show respondent voice
   - Use **bold** for emphasis on important words/metrics
   - Focus on insights decision-makers can act on
   - May reference response patterns if they reveal important insights (e.g., "those who selected X prioritize Y")

3. Style:
   - Professional, objective tone suitable for business/academic contexts
   - Direct quotes in "quotation marks" with proper context
   - Use **bold** strategically for emphasis (not excessively)
   - Maximum 120 words total
   - Response pattern references should be natural and add value, not forced

4. FORMATTING RULES (CRITICAL):
   - Use ONLY plain text and markdown syntax
   - For bold: **text** (double asterisks)
   - For emphasis: plain quotes "text" (no HTML tags)
   - DO NOT use HTML tags like <strong>, <em>, <b>, etc.
   - DO NOT add class attributes or any HTML
   - Output must be pure text with markdown only

CRITICAL: Return ONLY the formatted summary as plain text with markdown. No preamble, no "Here is...", no markdown code blocks, no HTML tags. Start directly with the opening paragraph.`;

      const summary = await this.aiService['invokeModelRaw'](prompt, false); // Use plain text, not JSON format
      return summary.trim();
    } catch (error) {
      console.error('[Analytics] Error generating summary:', error);
      // Fallback to basic summary with quote if available
      const sampleQuote = highlightedQuotes?.[0]?.text;
      const quoteText = sampleQuote ? ` One respondent noted: "${sampleQuote.substring(0, 80)}..."` : '';
      return `Analysis of ${responses.length} responses to "${form.title}". Top themes: ${topTopics.slice(0, 3).join(', ')}.${quoteText} Overall sentiment is ${sentimentDistribution.positive > 50 ? 'positive' : sentimentDistribution.negative > 50 ? 'negative' : 'neutral'}.`;
    }
  }
}
